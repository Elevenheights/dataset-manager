# UltraMuse Dataset Manager

Professional LoRA training dataset preparation tool with AI-powered captioning.

**âš¡ Want to get started fast? See [QUICKSTART.md](QUICKSTART.md)**

## ğŸŒŸ Features

- âœ… **ZIP Upload** - Drop your images once, extract automatically
- âœ… **AI Captioning** - Qwen 2.5 VL 7B generates detailed, training-optimized captions
- âœ… **Virtual Scrolling** - Handle 1000+ images smoothly
- âœ… **Batch Operations** - Caption, edit, and manage hundreds of images at once
- âœ… **Add/Remove** - Dynamically manage images in your dataset
- âœ… **AI Toolkit Export** - One-click export to training format
- âœ… **Dev + Prod** - Works locally and on RunPod

## ğŸš€ Quick Start

### Local Development (Windows)

**1. Start Dataset Manager**
```bash
cd dataset-manager
npm install
npm run dev
```
â†’ Open `http://localhost:3000`

**2. Start Caption Service** (Optional - for AI captioning)
```bash
# Copy .env.caption.example to .env.caption
# Set DEV_MODEL_PATH to your Qwen GGUF model location
start_caption_service.bat
```
â†’ Service runs on `http://localhost:11435`

### RunPod Production (True One-Click)

**Using the UltraMuse RunPod Template:**

1. Go to RunPod
2. Select **"UltraMuse Dataset Manager"** template
3. Click **"Deploy"**
4. Wait ~25 minutes â˜•

**Done!** Access your apps:
- Dataset Manager: `http://<runpod-url>:3000`
- AI Toolkit: `http://<runpod-url>:8675`

The template automatically:
- âœ… Downloads setup script from UltraMuse website
- âœ… Clones Dataset Manager, AI Toolkit, ComfyUI
- âœ… Downloads all models (~20GB): Qwen 2.5 VL, Z-Image-Turbo
- âœ… Installs dependencies and starts all services
- âœ… Everything runs in background

**No SSH, no commands, no configuration required.**

---

**For Advanced Users:** See deployment docs:
- [QUICKSTART.md](QUICKSTART.md) - Quick setup guide
- [RUNPOD_TEMPLATE.md](RUNPOD_TEMPLATE.md) - Template configuration
- [RUNPOD_DEPLOYMENT.md](RUNPOD_DEPLOYMENT.md) - Manual deployment
- [USAGE_EXAMPLE.md](USAGE_EXAMPLE.md) - Complete workflow

## ğŸ“– Documentation

- **[QUICKSTART.md](QUICKSTART.md)** â­ - Get running in 5 minutes
- **[DEV_SETUP.md](DEV_SETUP.md)** - Local development setup
- **[RUNPOD_TEMPLATE.md](RUNPOD_TEMPLATE.md)** - Template configuration
- **[RUNPOD_DEPLOYMENT.md](RUNPOD_DEPLOYMENT.md)** - Deployment guide
- **[USAGE_EXAMPLE.md](USAGE_EXAMPLE.md)** - Complete workflow
- **[ENV_FILES_NOTE.md](ENV_FILES_NOTE.md)** - Environment variables explained
- **[CAPTION_SERVICE_README.md](CAPTION_SERVICE_README.md)** - Caption service details

## â“ FAQ

**Q: Do I need to commit `.env.caption`?**  
A: **No!** It's in `.gitignore` and only for local dev. Production works without it.

**Q: Will the RunPod template work without configuration files?**  
A: **Yes!** Everything uses smart defaults. No .env files needed on RunPod.

**Q: Can I customize the deployment?**  
A: Yes, set `DATASET_MANAGER_REPO` environment variable to use your own fork.

## ğŸ”§ Tech Stack

**Frontend:**
- Next.js 16 (App Router)
- React 19
- Tailwind CSS 4
- TypeScript
- Virtual scrolling (`@tanstack/react-virtual`)

**Backend:**
- Next.js API Routes
- Node.js file system operations
- `node-stream-zip` for robust extraction

**AI Captioning:**
- Qwen 2.5 VL 7B (Q8 GGUF)
- llama-cpp-python (GPU accelerated)
- Flask API server

## ğŸ“¦ Project Structure

```
dataset-manager/
â”œâ”€â”€ src/                    # Next.js application
â”‚   â”œâ”€â”€ app/               # Pages and API routes
â”‚   â”œâ”€â”€ components/        # React components
â”‚   â”œâ”€â”€ lib/               # Utilities
â”‚   â””â”€â”€ types/             # TypeScript types
â”œâ”€â”€ data/                  # Local data storage
â”‚   â”œâ”€â”€ datasets/          # Processed datasets
â”‚   â”œâ”€â”€ uploads/           # Temporary uploads
â”‚   â””â”€â”€ exports/           # Dev mode exports
â”œâ”€â”€ caption_service.py     # Qwen caption service
â”œâ”€â”€ runpod_start.sh       # RunPod startup (automated)
â”œâ”€â”€ start_caption_service.bat  # Windows caption service
â””â”€â”€ package.json
```

## ğŸ¯ Workflow

1. **Upload** â†’ Drop ZIP with images
2. **Caption** â†’ AI generates descriptions or edit manually
3. **Manage** â†’ Add/remove images, search, filter
4. **Export** â†’ One-click to AI Toolkit format
5. **Train** â†’ Use exported dataset in AI Toolkit

## ğŸ”‘ Key Capabilities

### Dataset Management
- Upload multiple ZIPs
- Add images to existing datasets
- Delete selected images
- Search by filename or caption
- Filter by caption status

### AI Captioning
- Hardcoded Qwen 2.5 VL model
- Batch caption 100s of images
- Custom prompts supported
- Professional, training-optimized output

### Export
- **Dev Mode:** Exports to `./data/exports/`
- **Production:** Exports to `/workspace/ai-toolkit/datasets/`
- AI Toolkit format: `{dataset}/1_dataset/{image}.jpg + {image}.txt`

## âš™ï¸ Configuration

### Development
Create `.env.caption` for local caption service:
```bash
DEV_MODEL_PATH=C:\Models\Qwen2.5-VL-7B-Instruct-Q8_0.gguf
PORT=11435
N_GPU_LAYERS=-1
```

### Production (RunPod)
Environment is automatically configured by `runpod_start.sh`

## ğŸ†˜ Troubleshooting

### Upload fails with "Invalid filename"
- The new `node-stream-zip` handles this automatically
- Files with invalid characters are sanitized

### Caption service won't start
- **Dev:** Check `DEV_MODEL_PATH` in `.env.caption`
- **Prod:** Verify model downloaded: `/workspace/models/Qwen2.5-VL-7B-Instruct-Q8_0.gguf`

### Export doesn't work
- **Dev:** Always works (local folder)
- **Prod:** Check AI Toolkit models downloaded

## ğŸ“ Support

Join our Discord for:
- Free resources
- Early model access
- Support and troubleshooting

ğŸ”— https://discord.gg/9jVnQHDx

## ğŸ“„ License

Private project - UltraMuse

---

**Built with â¤ï¸ for the LoRA training community**
