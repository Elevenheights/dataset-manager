# System Architecture

## ðŸ—ï¸ Complete System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              RunPod Template (Your Website)             â”‚
â”‚  Downloads: runpod_start.sh â†’ Runs automatically       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  runpod_start.sh                        â”‚
â”‚  Orchestrates entire deployment automatically           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼               â–¼               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Clone  â”‚    â”‚ Download â”‚    â”‚  Setup   â”‚
    â”‚ Repos  â”‚    â”‚  Models  â”‚    â”‚ Services â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
         â”‚             â”‚               â”‚
         â–¼             â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Final Deployment (/workspace)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                              â”‚
â”‚  ðŸ“‚ dataset-manager/      (Port 3000)       â”‚
â”‚     â”œâ”€ Next.js UI                           â”‚
â”‚     â”œâ”€ caption_service.py                   â”‚
â”‚     â””â”€ data/                                â”‚
â”‚                                              â”‚
â”‚  ðŸ“‚ caption-service/      (Port 11435)      â”‚
â”‚     â”œâ”€ caption_service.py (deployed)        â”‚
â”‚     â”œâ”€ venv/                                â”‚
â”‚     â””â”€ Qwen 2.5 VL loaded                  â”‚
â”‚                                              â”‚
â”‚  ðŸ“‚ ai-toolkit/          (Port 8675)        â”‚
â”‚     â”œâ”€ Training UI                          â”‚
â”‚     â”œâ”€ datasets/  â† Exports go here         â”‚
â”‚     â””â”€ venv/                                â”‚
â”‚                                              â”‚
â”‚  ðŸ“‚ models/                                 â”‚
â”‚     â”œâ”€ Qwen2.5-VL-7B-Instruct-Q8_0.gguf    â”‚
â”‚     â”œâ”€ Z-Image-Turbo/                      â”‚
â”‚     â””â”€ zimage_turbo_training_adapter/      â”‚
â”‚                                              â”‚
â”‚  ðŸ“‚ ComfyUI/                                â”‚
â”‚     â””â”€ Inference tools                      â”‚
â”‚                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ”„ Data Flow

### Upload â†’ Caption â†’ Export â†’ Train

```
1. USER UPLOADS ZIP
   Dataset Manager (port 3000)
   â†“
   Extracts to: /workspace/dataset-manager/data/datasets/{id}/

2. AI CAPTIONS IMAGES
   Dataset Manager â†’ Caption Service API (port 11435)
   â†“
   Qwen 2.5 VL generates captions
   â†“
   Captions saved as .txt files alongside images

3. USER EXPORTS DATASET
   Dataset Manager copies files
   â†“
   /workspace/ai-toolkit/datasets/{name}/1_dataset/
   â”œâ”€ image1.jpg
   â”œâ”€ image1.txt
   â””â”€ ...

4. USER TRAINS LORA
   AI Toolkit UI (port 8675)
   â†“
   Reads from datasets/ folder
   â†“
   Trains using Z-Image-Turbo
   â†“
   Outputs trained LoRA
```

---

## ðŸŽ›ï¸ Service Communication

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Browser    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                                 â”‚
         â–¼                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Dataset Manager â”‚              â”‚  AI Toolkit UI  â”‚
â”‚  (Next.js)      â”‚              â”‚  (Node.js)      â”‚
â”‚  Port 3000      â”‚              â”‚  Port 8675      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ API calls
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Caption Service â”‚
â”‚  (Flask)        â”‚
â”‚  Port 11435     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ Model inference
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Qwen 2.5 VL    â”‚
â”‚  (GGUF Model)   â”‚
â”‚  GPU/CPU        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ’¾ Configuration Strategy

### Environment Detection
```python
# caption_service.py
DEV_MODEL_PATH = os.getenv('DEV_MODEL_PATH')

if DEV_MODEL_PATH:
    # Local development - uses .env.caption or environment variable
    MODEL_PATH = DEV_MODEL_PATH
else:
    # Production - hardcoded path
    MODEL_PATH = "/workspace/models/Qwen2.5-VL-7B-Instruct-Q8_0.gguf"
```

```typescript
// Next.js API routes
const isDev = process.env.NODE_ENV === 'development';

if (isDev) {
    exportPath = './data/exports/';
} else {
    exportPath = '/workspace/ai-toolkit/datasets/';
}
```

### No Config Files Needed
- âœ… Smart defaults for everything
- âœ… Environment detection (dev vs prod)
- âœ… Hardcoded production paths
- âœ… Optional override via environment variables

---

## ðŸ” What Goes in Git vs What Doesn't

### âœ… Committed to Git:
```
âœ“ Source code (src/)
âœ“ package.json, requirements.txt
âœ“ runpod_start.sh
âœ“ caption_service.py
âœ“ .env.caption.example (template only)
âœ“ Documentation (*.md)
âœ“ .gitignore
```

### âŒ NOT Committed (.gitignore):
```
âœ— .env.caption (local dev config)
âœ— node_modules/ (npm dependencies)
âœ— venv_caption/ (Python venv)
âœ— .next/ (build output)
âœ— data/ (user datasets)
âœ— *.log (log files)
```

### ðŸ“¦ Downloaded on Deployment:
```
â¬‡ node_modules/ (npm install)
â¬‡ venv/ (pip install)
â¬‡ Models (~20GB)
â¬‡ AI Toolkit (git clone)
â¬‡ ComfyUI (git clone)
```

---

## ðŸš€ Deployment Sequence

### RunPod Template Execution Order

```
1. RunPod creates container
   â””â”€> Base image: PyTorch + CUDA

2. Template runs start command
   â””â”€> wget runpod_start.sh from your website

3. runpod_start.sh executes
   â”œâ”€> Clones dataset-manager from git
   â”œâ”€> Clones ai-toolkit from GitHub
   â”œâ”€> Clones ComfyUI from GitHub
   â”œâ”€> Downloads models from HuggingFace
   â”œâ”€> npm install (dataset-manager)
   â”œâ”€> npm install (ai-toolkit/ui)
   â”œâ”€> pip install (caption service with CUDA)
   â”œâ”€> pip install (ai-toolkit)
   â”œâ”€> npm run build (dataset-manager)
   â”œâ”€> Deploys caption_service.py
   â”œâ”€> Starts caption service in background
   â”œâ”€> Starts dataset-manager in background
   â””â”€> Starts ai-toolkit UI in background

4. Services running
   â”œâ”€> Dataset Manager: http://localhost:3000
   â”œâ”€> Caption Service: http://localhost:11435
   â””â”€> AI Toolkit: http://localhost:8675

5. Container stays alive (tail -f /dev/null)
```

**Total time:** ~25 minutes (mostly model downloads)

---

## ðŸŽ¯ Zero-Config Philosophy

The entire system is designed for **zero configuration**:

1. **No .env files required** in production
2. **No manual path configuration** needed
3. **No service account setup** required
4. **No API keys** to configure (uses local models)
5. **Smart defaults** for everything
6. **Automatic environment detection** (dev vs prod)

**User clicks template â†’ Wait â†’ Use app**

That's it! ðŸŽ‰

---

## ðŸ”§ Advanced: Customization Points

If users want to customize:

**Fork the repository:**
```bash
# Set custom repo in template
export DATASET_MANAGER_REPO="https://github.com/UserFork/CustomVersion.git"
```

**Override model locations:**
```bash
# In template environment variables
export DEV_MODEL_PATH="/custom/path/to/model.gguf"
```

**Change ports:**
```bash
# In template start script
export PORT=3001  # Dataset Manager
export QWEN_PORT=11436  # Caption Service
```

But **99% of users won't need any customization** - defaults just work!

