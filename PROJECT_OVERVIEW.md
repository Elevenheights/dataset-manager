# UltraMuse Dataset Manager - Project Overview

**Professional LoRA training dataset preparation tool with AI-powered captioning and model management.**

---

## ğŸ“ Current Status (December 7, 2025)

### âœ… Production Ready Features
- **Dataset Management** - Upload, organize, and manage training datasets
- **AI Captioning** - Qwen 2.5 VL 7B generates professional captions
- **Model Manager** - Download and manage AI models from HuggingFace, CivitAI, or direct URLs
- **AI Toolkit Integration** - One-click export to AI Toolkit training format
- **Virtual Scrolling** - Handle 1000+ images smoothly
- **Docker Deployment** - Full containerized deployment with RunPod template

### ğŸ”§ Recent Updates (Latest Session)

**Model Download Progress Tracking (FIXED)**
- **Issue**: Progress bar stuck at 0% despite active downloads
- **Solution**: Implemented `.incomplete` file scanning (same as Qwen download)
- **Added**: Live network stats showing real-time download speed
- **Added**: User-friendly message explaining progress may pause during chunk transfers
- Files: `src/lib/models/downloader.ts`, `src/components/ModelDownloadProgress.tsx`, `src/app/api/system/network/route.ts`

**Previous Fixes**
- Image path resolution (Windows to Docker compatibility)
- Caption service status checking
- Bulk caption improvements
- Model cache unification with AI Toolkit

---

## ğŸ—ï¸ Architecture

### System Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Docker Container                       â”‚
â”‚                                                         â”‚
â”‚  ğŸ“¦ Dataset Manager (Port 3000)                        â”‚
â”‚     â”œâ”€ Next.js 16 Frontend                            â”‚
â”‚     â”œâ”€ API Routes (Backend)                           â”‚
â”‚     â””â”€ Data: /workspace/datasets/                     â”‚
â”‚                                                         â”‚
â”‚  ğŸ“¦ Caption Service (Port 11435)                       â”‚
â”‚     â”œâ”€ Flask API                                       â”‚
â”‚     â”œâ”€ Qwen 2.5 VL 7B Model                          â”‚
â”‚     â””â”€ llama-cpp-python (GPU)                         â”‚
â”‚                                                         â”‚
â”‚  ğŸ“¦ AI Toolkit (Port 8675)                             â”‚
â”‚     â”œâ”€ Training UI                                     â”‚
â”‚     â”œâ”€ Receives exports from Dataset Manager          â”‚
â”‚     â””â”€ Shares model cache                             â”‚
â”‚                                                         â”‚
â”‚  ğŸ“¦ Shared Model Storage                               â”‚
â”‚     â””â”€ /workspace/models/                             â”‚
â”‚         â”œâ”€ huggingface/ (Unified HF cache)           â”‚
â”‚         â”œâ”€ zimage/                                    â”‚
â”‚         â”œâ”€ flux/                                      â”‚
â”‚         â”œâ”€ sdxl/                                      â”‚
â”‚         â””â”€ qwen/                                      â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

```
1. Upload ZIP â†’ Extract to /workspace/datasets/{id}/
2. AI Caption â†’ Qwen service generates .txt files
3. Export â†’ Copy to /workspace/ai-toolkit/datasets/
4. Train â†’ AI Toolkit reads dataset for LoRA training
```

---

## ğŸ“‚ Project Structure

```
dataset-manager/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/                      # Next.js pages & API routes
â”‚   â”‚   â”œâ”€â”€ api/                  # Backend endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ datasets/         # Dataset CRUD
â”‚   â”‚   â”‚   â”œâ”€â”€ captions/         # Caption updates
â”‚   â”‚   â”‚   â”œâ”€â”€ images/           # Image management
â”‚   â”‚   â”‚   â”œâ”€â”€ models/           # Model manager API
â”‚   â”‚   â”‚   â”œâ”€â”€ ollama/           # Caption generation
â”‚   â”‚   â”‚   â”œâ”€â”€ export/           # AI Toolkit export
â”‚   â”‚   â”‚   â””â”€â”€ system/           # System status, network
â”‚   â”‚   â”œâ”€â”€ page.tsx              # Home page
â”‚   â”‚   â”œâ”€â”€ caption/              # Caption management UI
â”‚   â”‚   â”œâ”€â”€ models/               # Model manager UI
â”‚   â”‚   â”œâ”€â”€ train/                # Training config UI
â”‚   â”‚   â””â”€â”€ upload/               # Upload UI
â”‚   â”œâ”€â”€ components/               # React components
â”‚   â”‚   â”œâ”€â”€ BulkCaptionModal.tsx
â”‚   â”‚   â”œâ”€â”€ CaptionEditor.tsx
â”‚   â”‚   â”œâ”€â”€ ImageGrid.tsx
â”‚   â”‚   â”œâ”€â”€ ModelCard.tsx
â”‚   â”‚   â”œâ”€â”€ ModelDownloadProgress.tsx  # NEW: Live network stats
â”‚   â”‚   â””â”€â”€ ModelSelector.tsx
â”‚   â”œâ”€â”€ lib/                      # Business logic
â”‚   â”‚   â”œâ”€â”€ dataset.ts            # Dataset operations
â”‚   â”‚   â”œâ”€â”€ ollama.ts             # Caption service client
â”‚   â”‚   â”œâ”€â”€ zip.ts                # ZIP extraction
â”‚   â”‚   â””â”€â”€ models/               # Model management
â”‚   â”‚       â”œâ”€â”€ types.ts          # TypeScript types
â”‚   â”‚       â”œâ”€â”€ registry.ts       # Built-in model catalog
â”‚   â”‚       â”œâ”€â”€ storage.ts        # Model database & HF cache scan
â”‚   â”‚       â””â”€â”€ downloader.ts     # Multi-source downloads
â”‚   â””â”€â”€ types/                    # Global TypeScript types
â”œâ”€â”€ data/                         # Local development data
â”‚   â”œâ”€â”€ datasets/                 # Extracted datasets
â”‚   â”œâ”€â”€ uploads/                  # Temporary uploads
â”‚   â””â”€â”€ exports/                  # Dev mode exports
â”œâ”€â”€ caption_service.py            # Qwen caption Flask API
â”œâ”€â”€ download_model.py             # Python downloader (hf_transfer)
â”œâ”€â”€ docker_start.sh               # Docker entrypoint
â”œâ”€â”€ Dockerfile                    # Container definition
â”œâ”€â”€ package.json                  # Node.js dependencies
â””â”€â”€ requirements.txt              # Python dependencies

Documentation:
â”œâ”€â”€ README.md                     # Main readme
â”œâ”€â”€ PROJECT_OVERVIEW.md           # This file (consolidated docs)
â”œâ”€â”€ QUICKSTART.md                 # 5-minute setup guide
â”œâ”€â”€ ARCHITECTURE.md               # System architecture
â”œâ”€â”€ RUNPOD_TEMPLATE.md            # RunPod template config
â””â”€â”€ [Various fix summaries]       # Bug fix documentation
```

---

## ğŸš€ Quick Start

### Local Development (Windows)

```powershell
# 1. Start Dataset Manager
cd dataset-manager
npm install
npm run dev
# Opens: http://localhost:3000

# 2. (Optional) Start Caption Service
# First time: Copy .env.caption.example â†’ .env.caption
# Set: DEV_MODEL_PATH=C:\Path\To\Qwen2.5-VL-7B-Instruct-Q8_0.gguf
start_caption_service.bat
# Runs on: http://localhost:11435
```

### Docker (Production)

```powershell
docker build -t ultramuse-dataset-manager:latest .
docker run -d --name dataset-manager \
  -p 3000:3000 -p 11435:11435 -p 8675:8675 \
  -v dataset-manager-data:/workspace \
  ultramuse-dataset-manager:latest
```

### RunPod (One-Click)

1. Select **"UltraMuse Dataset Manager"** template
2. Click **Deploy**
3. Wait ~25 minutes â˜•
4. Access: `http://<runpod-url>:3000`

**All services auto-start:** Dataset Manager, Caption Service, AI Toolkit UI

---

## ğŸ¯ Features

### Dataset Management
- âœ… Upload multiple ZIP files
- âœ… Add/remove images dynamically
- âœ… Search by filename or caption
- âœ… Filter by caption status
- âœ… Virtual scrolling (1000+ images)
- âœ… Bulk operations

### AI Captioning
- âœ… Qwen 2.5 VL 7B (8B Q8 GGUF)
- âœ… Single or bulk caption generation
- âœ… Custom prompt support
- âœ… Professional, training-optimized output
- âœ… GPU acceleration (llama-cpp-python)

### Model Manager
- âœ… Built-in model registry (Z-Image, Flux, SDXL, Qwen)
- âœ… Download from HuggingFace, CivitAI, direct URLs
- âœ… Upload local model files
- âœ… **Live download progress with network stats** (NEW)
- âœ… Unified HF cache (shared with AI Toolkit)
- âœ… Disk usage tracking
- âœ… Token support for gated models

### Export Integration
- âœ… One-click export to AI Toolkit format
- âœ… Select base model for training
- âœ… Automatic directory structure
- âœ… ZIP export for portability
- âœ… Dev/prod environment detection

---

## ğŸ”§ Tech Stack

**Frontend:**
- Next.js 16 (App Router)
- React 19
- Tailwind CSS 4
- TypeScript
- Virtual scrolling (`@tanstack/react-virtual`)

**Backend:**
- Next.js API Routes
- Node.js file operations
- `node-stream-zip` for ZIP handling
- Python subprocess for downloads

**AI Services:**
- Qwen 2.5 VL 7B (Q8 GGUF)
- llama-cpp-python (GPU)
- Flask API server
- hf_transfer for fast downloads

**Infrastructure:**
- Docker containerization
- RunPod template deployment
- Volume-based persistence

---

## ğŸ“Š Key Workflows

### Complete Training Pipeline

```
1. UPLOAD
   User uploads ZIP â†’ Extracts to dataset folder

2. CAPTION
   AI generates descriptions â†’ Saves as .txt files

3. MANAGE
   User edits captions, adds/removes images

4. EXPORT
   One-click â†’ AI Toolkit datasets folder
   Format: {dataset}/1_dataset/{image}.jpg + {image}.txt

5. TRAIN
   AI Toolkit â†’ Trains LoRA using Z-Image or Flux

6. INFERENCE
   Use trained LoRA in ComfyUI or other tools
```

### Model Management

```
DOWNLOAD:
  HuggingFace â†’ hf_transfer (fast parallel)
  CivitAI â†’ Direct API download
  Direct URL â†’ Standard HTTPS download
  Local â†’ File upload
  â†“
  Organized storage: /workspace/models/{family}/
  â†“
  Tracked in: installed-models.json
  â†“
  Auto-discovery: Scans HF cache for AI Toolkit models

PROGRESS TRACKING:
  Python writes progress â†’ /tmp/download_*.json
  TypeScript scans .incomplete files (hf_transfer)
  UI polls every 1s â†’ Updates progress bar
  NEW: Live network stats â†’ Shows actual download speed
```

---

## ğŸ” Configuration

### Environment Detection

```typescript
// Automatic dev vs prod detection
const isDev = process.env.NODE_ENV === 'development';

// Dev mode
if (isDev) {
  CAPTION_SERVICE_URL = 'http://localhost:11435'
  EXPORT_PATH = './data/exports/'
  MODEL_PATH = process.env.DEV_MODEL_PATH
}

// Production mode
else {
  CAPTION_SERVICE_URL = 'http://localhost:11435'
  EXPORT_PATH = '/workspace/ai-toolkit/datasets/'
  MODEL_PATH = '/workspace/models/Qwen2.5-VL-7B-Instruct-Q8_0.gguf'
}
```

### Files Needed

**Development:**
- `.env.caption` (optional, for local caption service)
- No other config files needed

**Production:**
- No config files needed! All paths hardcoded

**Git (.gitignore):**
- `.env.caption` âŒ (local only)
- `node_modules/` âŒ
- `data/` âŒ
- `.next/` âŒ

---

## ğŸ†˜ Troubleshooting

### Model Download Issues

**Progress stuck at 0%:**
- âœ… FIXED: Now scans .incomplete files
- âœ… NEW: Shows live network stats to confirm download
- Check: Network indicator shows download speed

**Download seems frozen:**
- Check: "Last update: Xs ago" in logs
- Normal: Progress may pause during chunk writes
- Warning: If >30s with no file activity

### Caption Service

**Not starting:**
- Dev: Check `DEV_MODEL_PATH` in `.env.caption`
- Prod: Verify model exists at `/workspace/models/Qwen2.5-VL-7B-Instruct-Q8_0.gguf`
- Check: `curl http://localhost:11435/health`

**Slow generation:**
- Expected: ~5-15s per image (CPU mode)
- GPU: ~1-3s per image (CUDA enabled)
- Bulk: Processes sequentially

### Image Path Issues

**Images not displaying:**
- âœ… FIXED: Now stores relative paths only
- Old datasets: May need path fix script (see FIXES_SUMMARY.md)
- Check: metadata.json should have filenames, not full paths

---

## ğŸ“ˆ Performance

### Benchmarks

**Dataset Operations:**
- ZIP upload (1000 images): ~30-60s
- Virtual scrolling: Handles 5000+ images smoothly
- Search/filter: Instant (<100ms)

**AI Captioning:**
- Single image (GPU): 1-3s
- Single image (CPU): 5-15s
- Bulk 100 images (GPU): 2-5 minutes
- Bulk 100 images (CPU): 8-15 minutes

**Model Downloads:**
- HuggingFace (hf_transfer): 50-200 MB/s
- CivitAI: 20-100 MB/s (varies)
- Direct URL: Depends on source

**Disk Usage:**
- Dataset Manager: ~50 MB
- Caption Service: ~200 MB
- Qwen Model: 8.5 GB
- Z-Image Models: ~9.3 GB
- Flux Models: ~24 GB each
- User datasets: Varies

---

## ğŸ”® Roadmap

### Planned Features
- [ ] Model quantization tools
- [ ] Automatic tag generation (Danbooru/e621 style)
- [ ] Image editing (crop, resize, rotate)
- [ ] Dataset versioning
- [ ] Multi-user support
- [ ] Cloud storage integration (S3, etc.)
- [ ] Advanced search (semantic, visual similarity)
- [ ] Dataset analytics dashboard

### Under Consideration
- [ ] Video dataset support
- [ ] Audio caption generation
- [ ] Custom model fine-tuning UI
- [ ] Collaborative captioning
- [ ] API for external tools
- [ ] Plugin system

---

## ğŸ“ Support & Community

**Discord:** https://discord.gg/4zbGm5j6jW
- Free resources
- Early model access
- Support and troubleshooting
- Community datasets

**Repository:** Private (UltraMuse)

**Documentation:**
- `README.md` - Main readme
- `QUICKSTART.md` - Quick setup
- `ARCHITECTURE.md` - System design
- `RUNPOD_TEMPLATE.md` - Deployment template
- `FIXES_SUMMARY.md` - Bug fix history

---

## ğŸ“„ License

Private project - UltraMuse  
Built with â¤ï¸ for the LoRA training community

---

## ğŸ“ Development Notes

### Adding New Features

**New API Endpoint:**
1. Create route in `src/app/api/{feature}/route.ts`
2. Implement GET/POST/PUT/DELETE handlers
3. Use TypeScript types from `src/types/`
4. Return `NextResponse.json()`

**New Model Source:**
1. Add download method in `src/lib/models/downloader.ts`
2. Update `ModelDefinition` type if needed
3. Add to registry in `src/lib/models/registry.ts`
4. Update UI in `src/components/AddCustomModelForm.tsx`

**New UI Component:**
1. Create in `src/components/`
2. Use Tailwind + CSS variables for theming
3. Keep components small and focused
4. Export as default

### Code Style

- **TypeScript:** Strict mode, explicit types
- **React:** Functional components, hooks
- **API Routes:** Error handling with try/catch
- **Naming:** camelCase (variables), PascalCase (components)
- **Comments:** Explain "why", not "what"

### Testing Locally

```powershell
# Development server
npm run dev

# Production build
npm run build
npm start

# Docker test
.\rebuild-and-restart.ps1
```

---

**Last Updated:** December 7, 2025  
**Version:** 1.5.0  
**Status:** Production Ready âœ…

